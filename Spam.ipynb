{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/Mirela/PycharmProjects/App/spam/train.csv').fillna(' ')\n",
    "valid_df = pd.read_csv('C:/Users/Mirela/PycharmProjects/App/spam/valid.csv').fillna(' ')\n",
    "test_df = pd.read_csv('C:/Users/Mirela/PycharmProjects/App/spam/test.csv').fillna(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i m in solihull  | do you want anything</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gud mrng dear hav a nice day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dude how do you like the buff wind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yup  wun believe wat  u really neva c e msg i ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did you get any gift  this year i didnt get an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>hi  wlcome back  did wonder if you got eaten b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>sorry  i ll call later</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>prabha  i m soryda  realy  frm heart i m sory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>nt joking seriously i told</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>did he just say somebody is named tampa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4736 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0              i m in solihull  | do you want anything       1\n",
       "1                          gud mrng dear hav a nice day      1\n",
       "2                   dude how do you like the buff wind       1\n",
       "3     yup  wun believe wat  u really neva c e msg i ...      1\n",
       "4     did you get any gift  this year i didnt get an...      1\n",
       "...                                                 ...    ...\n",
       "4731  hi  wlcome back  did wonder if you got eaten b...      1\n",
       "4732                             sorry  i ll call later      1\n",
       "4733      prabha  i m soryda  realy  frm heart i m sory      1\n",
       "4734                         nt joking seriously i told      1\n",
       "4735            did he just say somebody is named tampa      1\n",
       "\n",
       "[4736 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4736 entries, 0 to 4735\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    4736 non-null   object\n",
      " 1   label   4736 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 74.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 585 entries, 0 to 584\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    585 non-null    object\n",
      " 1   label   585 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.3+ KB\n"
     ]
    }
   ],
   "source": [
    "valid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    9 non-null      object\n",
      " 1   label   9 non-null      int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 272.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_df['text']\n",
    "valid_text = valid_df['text']\n",
    "test_text = test_df['text']\n",
    "all_text = pd.concat([train_text,valid_text,test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4736,)\n",
      "(585,)\n",
      "(9,)\n",
      "(4736, 12000)\n",
      "(585, 12000)\n",
      "(9, 12000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2),min_df=2,max_features=12000)\n",
    "\n",
    "vectorizer = vectorizer.fit(all_text)\n",
    "train_features = vectorizer.transform(train_text)\n",
    "valid_features = vectorizer.transform(valid_text)\n",
    "test_features = vectorizer.transform(test_text)\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "print(train_features.shape)\n",
    "print(valid_features.shape)\n",
    "print(test_features.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0).fit(train_features, y_train)\n",
    "y_pred_clf=lr.predict(valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy score is 0.9623931623931624'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\"Accuracy score is {}\".format(accuracy_score(y_valid,y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy score is 0.9623931623931624'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn = MultinomialNB()\n",
    "mn.fit(train_features, y_train)\n",
    "y_pred_mn=mn.predict(valid_features)\n",
    "\"Accuracy score is {}\".format(accuracy_score(y_valid,y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy score is 0.9641025641025641'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0).fit(train_features, y_train)\n",
    "y_pred_clf=dt.predict(valid_features)\n",
    "\"Accuracy score is {}\".format(accuracy_score(y_valid,y_pred_clf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy score is 0.9863247863247864'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=0).fit(train_features, y_train)\n",
    "y_pred_clf=svc.predict(valid_features)\n",
    "\"Accuracy score is {}\".format(accuracy_score(y_valid,y_pred_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best classifier  is  : mn - MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision score is 0.975517890772128'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\"Precision score is {}\".format(precision_score(y_valid,y_pred_mn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recall score is 1.0'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\"Recall score is {}\".format(recall_score(y_valid,y_pred_mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f1 score is 0.9876072449952336'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\"f1 score is {}\".format(f1_score(y_valid,y_pred_mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 54,   0],\n",
       "       [ 13, 518]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(mn.predict(valid_features), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true positives (TP) = 518: These are cases in which we predicted yes (they have the spam), and they do have the spam.\n",
    "\n",
    "true negatives (TN) = 54 : We predicted no, and they don't have the spam. \n",
    "\n",
    "false positives (FP) = 0: We predicted yes, but they don't actually have the spam. (Also known as a \"Type I error.\") \n",
    "\n",
    "false negatives (FN) = 13: We predicted no, but they actually do have the spam. (Also known as a \"Type II error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99811424, 0.99158126, 0.93798258, 0.97991807, 0.98660516,\n",
       "       0.3437895 , 0.93497377, 0.99046041, 0.98272141, 0.9877606 ,\n",
       "       0.98367702, 0.99732368, 0.99788503, 0.99504164, 0.99257903,\n",
       "       0.99846553, 0.02166372, 0.98045021, 0.90952619, 0.99355996,\n",
       "       0.00101944, 0.99537018, 0.94847102, 0.9749498 , 0.97006802,\n",
       "       0.98440352, 0.94715742, 0.01006353, 0.86216391, 0.97066818,\n",
       "       0.98852855, 0.97417321, 0.98970752, 0.99919086, 0.99469794,\n",
       "       0.98842492, 0.98693716, 0.95442558, 0.97527199, 0.9998968 ,\n",
       "       0.98443318, 0.98500271, 0.00424268, 0.98656009, 0.98754059,\n",
       "       0.25535414, 0.99291608, 0.99962449, 0.99831772, 0.99262517,\n",
       "       0.92125855, 0.99735784, 0.97620124, 0.99406973, 0.99500968,\n",
       "       0.96908463, 0.01806679, 0.96343802, 0.9481767 , 0.99521255,\n",
       "       0.03042059, 0.99172681, 0.9982861 , 0.98068345, 0.13814138,\n",
       "       0.97414555, 0.96785272, 0.98184815, 0.98364316, 0.96140106,\n",
       "       0.98449819, 0.99640313, 0.99507404, 0.99909225, 0.67667453,\n",
       "       0.98668752, 0.96875109, 0.98797801, 0.96161683, 0.99394593,\n",
       "       0.99530146, 0.98851563, 0.99731372, 0.8943775 , 0.96745957,\n",
       "       0.99800037, 0.99828895, 0.96492177, 0.98332977, 0.96189325,\n",
       "       0.99588616, 0.95613336, 0.99750173, 0.99329877, 0.98785511,\n",
       "       0.99486912, 0.98726251, 0.87377086, 0.99781674, 0.96412953,\n",
       "       0.42502005, 0.94541893, 0.96557444, 0.99777923, 0.99132384,\n",
       "       0.97149048, 0.02677672, 0.99552228, 0.99025884, 0.99388421,\n",
       "       0.96350923, 0.9990253 , 0.5464834 , 0.9959192 , 0.9982589 ,\n",
       "       0.9938991 , 0.98320759, 0.96192758, 0.99648394, 0.98728818,\n",
       "       0.97403562, 0.99629812, 0.99941155, 0.87322799, 0.01205214,\n",
       "       0.97623551, 0.0906693 , 0.99700529, 0.99489433, 0.95240769,\n",
       "       0.98533907, 0.99264345, 0.99598329, 0.14110385, 0.95888755,\n",
       "       0.98415131, 0.99678479, 0.98964082, 0.98595979, 0.99882346,\n",
       "       0.00383286, 0.97254632, 0.99861327, 0.95033173, 0.02983254,\n",
       "       0.33593404, 0.01906051, 0.98436016, 0.99770208, 0.98974118,\n",
       "       0.95630325, 0.99760733, 0.90556098, 0.06800307, 0.02795601,\n",
       "       0.99332106, 0.9839079 , 0.99255351, 0.99750037, 0.99776959,\n",
       "       0.99675232, 0.97098402, 0.96966214, 0.95511655, 0.95333853,\n",
       "       0.99610359, 0.18843198, 0.99166242, 0.99560486, 0.97351465,\n",
       "       0.89565085, 0.99950891, 0.25774897, 0.99792363, 0.99509173,\n",
       "       0.99443281, 0.03607434, 0.98579532, 0.99857577, 0.99267169,\n",
       "       0.99868095, 0.98270697, 0.98773417, 0.98037363, 0.99564933,\n",
       "       0.9583291 , 0.94571262, 0.99869651, 0.95001167, 0.99693372,\n",
       "       0.9925391 , 0.98904983, 0.98395561, 0.02677672, 0.00396405,\n",
       "       0.96477934, 0.89129385, 0.98946213, 0.99449725, 0.96512497,\n",
       "       0.99893926, 0.98798099, 0.9926308 , 0.92512045, 0.98692343,\n",
       "       0.98898435, 0.9914851 , 0.99365599, 0.9942571 , 0.93631428,\n",
       "       0.99616033, 0.989278  , 0.98401588, 0.88377976, 0.98758128,\n",
       "       0.98142581, 0.97180141, 0.97934949, 0.99218875, 0.3320352 ,\n",
       "       0.97924257, 0.98222971, 0.86486486, 0.9961477 , 0.99442288,\n",
       "       0.97633034, 0.98982595, 0.9851544 , 0.9918062 , 0.99985505,\n",
       "       0.99870127, 0.99832891, 0.96656216, 0.98587661, 0.96570007,\n",
       "       0.99635545, 0.98941763, 0.97147319, 0.97178839, 0.99687831,\n",
       "       0.97772567, 0.98769589, 0.36141905, 0.99610855, 0.25535414,\n",
       "       0.98849217, 0.88747014, 0.98824668, 0.99112163, 0.97031241,\n",
       "       0.99878914, 0.99300528, 0.06074585, 0.99066204, 0.99547325,\n",
       "       0.99133662, 0.99710718, 0.99270803, 0.06157155, 0.98340003,\n",
       "       0.97660966, 0.98047417, 0.96270523, 0.0124194 , 0.99807237,\n",
       "       0.95764706, 0.99564775, 0.99714935, 0.95670361, 0.97658363,\n",
       "       0.97465818, 0.99693264, 0.98957452, 0.99589717, 0.99149256,\n",
       "       0.99486335, 0.99290267, 0.99033664, 0.98614469, 0.99935984,\n",
       "       0.86637944, 0.99022761, 0.98716471, 0.98154967, 0.97675121,\n",
       "       0.97664772, 0.9612286 , 0.99026204, 0.97988645, 0.9975453 ,\n",
       "       0.98439589, 0.95562321, 0.99922682, 0.99637447, 0.99802741,\n",
       "       0.96834779, 0.99526902, 0.98998592, 0.99520134, 0.96272733,\n",
       "       0.99468191, 0.99572029, 0.99167925, 0.97296799, 0.99181078,\n",
       "       0.99298354, 0.97520822, 0.98111271, 0.97911295, 0.98004003,\n",
       "       0.99652807, 0.95030767, 0.99801112, 0.98819814, 0.99369679,\n",
       "       0.99784716, 0.99719642, 0.99322925, 0.98819855, 0.97952383,\n",
       "       0.34098546, 0.98837457, 0.99957795, 0.99757578, 0.98465172,\n",
       "       0.98476173, 0.99587628, 0.34042142, 0.99259787, 0.43824751,\n",
       "       0.99399705, 0.9904371 , 0.99124403, 0.95144171, 0.99029529,\n",
       "       0.97208234, 0.13088482, 0.97268714, 0.99160881, 0.03527773,\n",
       "       0.90721248, 0.96087529, 0.00812393, 0.62154512, 0.42502005,\n",
       "       0.99261775, 0.93809159, 0.00812135, 0.21030964, 0.99340626,\n",
       "       0.88412472, 0.99756405, 0.9986287 , 0.99259305, 0.99785698,\n",
       "       0.99324184, 0.97535721, 0.99668768, 0.97763459, 0.97908278,\n",
       "       0.99459757, 0.99894378, 0.99508009, 0.96085061, 0.99693889,\n",
       "       0.97131719, 0.97481423, 0.98295213, 0.9835465 , 0.99008864,\n",
       "       0.99557508, 0.97117333, 0.13809643, 0.95757139, 0.98161349,\n",
       "       0.82763618, 0.99292616, 0.99119406, 0.28544805, 0.9943641 ,\n",
       "       0.98452109, 0.99635463, 0.97274844, 0.86486486, 0.98550803,\n",
       "       0.9862657 , 0.99179241, 0.99249983, 0.95937481, 0.98896295,\n",
       "       0.99433826, 0.99419193, 0.99833751, 0.99957737, 0.99516456,\n",
       "       0.99476931, 0.99449995, 0.96682779, 0.99898505, 0.9758222 ,\n",
       "       0.99173452, 0.98012009, 0.99235173, 0.98625728, 0.99803538,\n",
       "       0.99553223, 0.99783117, 0.98942308, 0.99084541, 0.9937998 ,\n",
       "       0.99519014, 0.99813421, 0.99419305, 0.98426773, 0.99756562,\n",
       "       0.97185686, 0.97900795, 0.90190516, 0.99737384, 0.98057005,\n",
       "       0.98682839, 0.99723847, 0.99247118, 0.99565437, 0.97564417,\n",
       "       0.99648474, 0.9447336 , 0.9890038 , 0.98644598, 0.99613389,\n",
       "       0.97937614, 0.97090037, 0.98408273, 0.98363588, 0.98733769,\n",
       "       0.97194501, 0.99670651, 0.00823761, 0.00782991, 0.97408407,\n",
       "       0.97709213, 0.97594415, 0.96911001, 0.99317139, 0.99941155,\n",
       "       0.99751317, 0.99016605, 0.99829033, 0.99831581, 0.96586567,\n",
       "       0.98936007, 0.9920322 , 0.99254309, 0.98912329, 0.97483902,\n",
       "       0.9924334 , 0.98628141, 0.95889228, 0.99587636, 0.76126784,\n",
       "       0.97138505, 0.97604411, 0.9948246 , 0.9870672 , 0.99684367,\n",
       "       0.99941155, 0.04519633, 0.99710567, 0.97048985, 0.99219644,\n",
       "       0.9949205 , 0.98788903, 0.98943536, 0.98374058, 0.91090331,\n",
       "       0.0344874 , 0.99535475, 0.30917145, 0.95725797, 0.99867919,\n",
       "       0.9965763 , 0.98907897, 0.13204849, 0.9819692 , 0.68710519,\n",
       "       0.99306921, 0.99573171, 0.97768076, 0.99371297, 0.96859505,\n",
       "       0.92630725, 0.99835199, 0.00295028, 0.94461798, 0.99147956,\n",
       "       0.00579018, 0.99769389, 0.69048785, 0.99530613, 0.99410396,\n",
       "       0.99353999, 0.98625123, 0.92929697, 0.96849602, 0.99475876,\n",
       "       0.99135984, 0.99780417, 0.98547263, 0.97438406, 0.99683593,\n",
       "       0.98226942, 0.98943287, 0.99646862, 0.91423682, 0.98651928,\n",
       "       0.99638495, 0.97994933, 0.97343707, 0.97609567, 0.03235095,\n",
       "       0.99006683, 0.97006802, 0.98650013, 0.99744283, 0.98269865,\n",
       "       0.98141551, 0.98201241, 0.9849471 , 0.97038368, 0.99822844,\n",
       "       0.94578403, 0.96992079, 0.85041161, 0.97686465, 0.98528398,\n",
       "       0.99575921, 0.99591595, 0.99149256, 0.02408684, 0.9794889 ,\n",
       "       0.99468284, 0.99630853, 0.95682183, 0.00275387, 0.98786727,\n",
       "       0.98233884, 0.24885782, 0.98823766, 0.97998458, 0.98943426,\n",
       "       0.9766124 , 0.99842374, 0.97875161, 0.96436905, 0.98451752,\n",
       "       0.99184924, 0.99364396, 0.98642355, 0.9938649 , 0.99004283,\n",
       "       0.99941155, 0.99272621, 0.94317001, 0.98684033, 0.99462853,\n",
       "       0.99574095, 0.9642951 , 0.99573631, 0.99802315, 0.99164398,\n",
       "       0.99778152, 0.99568894, 0.95979025, 0.99748247, 0.9573659 ,\n",
       "       0.94032527, 0.97054111, 0.98847212, 0.99716496, 0.99551208,\n",
       "       0.99549293, 0.99865511, 0.99455461, 0.99491946, 0.95474939])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn.predict_proba(valid_features)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predictions of our classifier are:[0.99158126 0.06157155 0.99046041 0.5464834  0.9877606  0.98660516\\n 0.3437895  0.42502005 0.98272141]'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mn.predict_proba(test_features)[:, 1]\n",
    "\"Predictions of our classifier are:{}\".format(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions: \n",
    "Best classifier here is multinomialNB. I decided to calculate some metrics like precision_score, recall_score, f1_score. At the and I made some predictions for the test set. For this example, I used TfidfVectorizer to convert a collection of raw documents into a matrix of TF-IDF features. I decided to use the next classifiers : LogisticRegression, MultinomialNB,DecisionTreeClassifier, LinearSVC. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
